{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installing the requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvQIfrzE25Hu",
        "outputId": "d62fa410-a300-45ce-e431-4e7c76ca9c97"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.19.3\n",
        "!pip install mediapipe\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install natsorted\n",
        "!pip install pandas\n",
        "!pip install plotly\n",
        "!pip install seaborn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up automatic reload for the scripts that will be written outside the jupyter notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzUeDmrg4xGU"
      },
      "outputs": [],
      "source": [
        "from base64 import b64encode\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from natsort import natsorted\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from typing import List # I don't think I need this!\n",
        "\n",
        "# Custom imports\n",
        "from pose_tracking_utils import *"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up all the necessary variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "VIDEO_PATH = \"./videos/clip_training_session_2.mp4\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMAKyQ893kSr",
        "outputId": "fca8834b-9067-4e39-ea50-a60077199030"
      },
      "source": [
        "Now we create the pose tracking video to visualize the joints and connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For webcam input:\n",
        "output_path = create_pose_tracking_video(VIDEO_PATH)\n",
        "print(output_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compress the video and visualize it on jupyter notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#compressed_path = save_compressed_video(output_path)\n",
        "compressed_path = \"./videos/clip_pose_training_compressed.mp4\"\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the landmark 3D plot animation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wk_RmGfWzg4",
        "outputId": "838fcb67-df47-41e2-b353-1e0d5a62771d"
      },
      "outputs": [],
      "source": [
        "create_landmarks_plot3D_animation(VIDEO_PATH, \"clip_pose_training.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compressed_path = save_compressed_video(\"clip_pose_training.mp4\")\n",
        "# Show video\n",
        "mp4 = open(compressed_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pose landmarks are this:\n",
        "\n",
        "Another list of pose landmarks in world coordinates. Each landmark consists of the following:\n",
        "\n",
        "x, y and z: Real-world 3D coordinates in meters with the origin at the center between hips.\n",
        "visibility: Identical to that defined in the corresponding\n",
        "\n",
        "[source](https://google.github.io/mediapipe/solutions/pose.html)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the reference plot against which we will set objectives to improve\n",
        "the desired movements. Like for example I am using olympiam judokas\n",
        "as my reference to improve my uchimata movement.\n",
        "\n",
        "(*This function and the interactive widget are not finished*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pose_coords = get_pose_coords(video_path=VIDEO_PATH)\n",
        "# remove all nones from a list\n",
        "pose_coords = [x for x in pose_coords if x is not None]\n",
        "print(\"Length of the list with the pose coordinates: \",len(pose_coords))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's plot the x,y,z coordinates separately in time: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "right_foot_coords = [pose_coords[i].landmark[31] for i in range(len(pose_coords))]\n",
        "# Extract x, y, z coordinates from right and right foot\n",
        "x_coords = [coord.x for coord in right_foot_coords]\n",
        "y_coords = [coord.y for coord in right_foot_coords]\n",
        "z_coords = [coord.z for coord in right_foot_coords]\n",
        "\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title('Foot Movement Over Time')\n",
        "ax.scatter(x_coords, y_coords, z_coords);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 3 separate plots showing each coordinates in time\n",
        "fig, axs = plt.subplots(3, 1, figsize=(10, 10))\n",
        "axs[0].plot(x_coords)\n",
        "axs[0].set_title('X Coordinate')\n",
        "axs[1].plot(y_coords)\n",
        "axs[1].set_title('Y Coordinate')\n",
        "axs[2].plot(z_coords)\n",
        "axs[2].set_title('Z Coordinate')\n",
        "plt.tight_layout();"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we create a 3D plot animation for body parts (in this case for the feet)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x_coords = [coord.x for coord in left_foot_coords]\n",
        "# y_coords = [coord.y for coord in left_foot_coords]\n",
        "# z_coords = [coord.z for coord in left_foot_coords]\n",
        "\n",
        "# x_coords_right = [coord.x for coord in right_foot_coords]\n",
        "# y_coords_right = [coord.y for coord in right_foot_coords]\n",
        "# z_coords_right = [coord.z for coord in right_foot_coords]\n",
        "\n",
        "# # Create a 3D scatter plot\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(111, projection='3d')\n",
        "# ax.set_xlabel('X')\n",
        "# ax.set_ylabel('Y')\n",
        "# ax.set_zlabel('Z')\n",
        "# ax.set_title('Foot Movement Over Time')\n",
        "\n",
        "# def update(frame):\n",
        "#     ax.clear()\n",
        "#     ax.set_xlabel('X')\n",
        "#     ax.set_ylabel('Y')\n",
        "#     ax.set_zlabel('Z')\n",
        "#     ax.set_title('Foot Movement Over Time')\n",
        "#     ax.scatter(x_coords[:frame], y_coords[:frame], z_coords[:frame])\n",
        "#     ax.scatter(x_coords_right[:frame], y_coords_right[:frame], z_coords_right[:frame])\n",
        "\n",
        "# ani = FuncAnimation(fig, update, frames=len(x_coords), interval=5)\n",
        "# ani.save('animation.mp4', writer='ffmpeg', fps=30)\n",
        "# #plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nicer looking landdmark plot of specific moments of the video, using plotly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plot_landmarks(pose_coords[200].pose_landmarks,  mp_pose.POSE_CONNECTIONS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a trace visualization\n",
        "VIDEO_PATH = \"./videos/uchimata_wall.mp4\"\n",
        "create_joint_trace(VIDEO_PATH,31, color_rgb=(0,255,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(VIDEO_PATH)\n",
        "create_joint_trace_video(VIDEO_PATH,31, color_rgb=(255,0,0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realtime updating line plot of the x,y,z coordinates of the body parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose model\n",
        "body_part_index = 32\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Initialize OpenCV VideoCapture object to capture video from the camera\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "# Create an empty list to store the trace of the right elbow\n",
        "trace = []\n",
        "\n",
        "# Create empty lists to store the x, y, z coordinates of the right elbow\n",
        "x_vals = []\n",
        "y_vals = []\n",
        "z_vals = []\n",
        "\n",
        "# Create a Matplotlib figure and subplot for the real-time updating plot\n",
        "# fig, ax = plt.subplots()\n",
        "# plt.title('Time Lapse of the X Coordinate')\n",
        "# plt.xlabel('Frames')\n",
        "# plt.ylabel('Coordinate Value')\n",
        "# plt.xlim(0,1)\n",
        "# plt.ylim(0,1)\n",
        "# plt.ion()\n",
        "# plt.show()\n",
        "frame_num = 0\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video capture\n",
        "    success, image = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "    # Convert the frame to RGB format\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame with MediaPipe Pose model\n",
        "    results = pose.process(image)\n",
        "\n",
        "    # Check if any body parts are detected\n",
        "    \n",
        "    if results.pose_landmarks:\n",
        "        # Get the x,y,z coordinates of the right elbow\n",
        "        x, y, z = results.pose_landmarks.landmark[body_part_index].x, results.pose_landmarks.landmark[body_part_index].y, results.pose_landmarks.landmark[body_part_index].z\n",
        "        \n",
        "        # Append the x, y, z values to the corresponding lists\n",
        "        #x_vals.append(x)\n",
        "        y_vals.append(y)\n",
        "        #z_vals.append(z)\n",
        "        \n",
        "        # # Add the (x, y) coordinates to the trace list\n",
        "        trace.append((int(x * image.shape[1]), int(y * image.shape[0])))\n",
        "\n",
        "        # Draw the trace on the image\n",
        "        for i in range(len(trace)-1):\n",
        "            cv2.line(image, trace[i], trace[i+1], (255, 0, 0), thickness=2)\n",
        "\n",
        "        plt.title('Time Lapse of the Y Coordinate')\n",
        "        plt.xlabel('Frames')\n",
        "        plt.ylabel('Coordinate Value')\n",
        "        plt.xlim(0,len(pose_coords))\n",
        "        plt.ylim(0,1)\n",
        "        plt.plot(y_vals);\n",
        "        # Clear the plot and update with the new x, y, z coordinate values\n",
        "        #ax.clear()\n",
        "        # ax.plot(range(0, frame_num + 1), x_vals, 'r.', label='x')\n",
        "        # ax.plot(range(0, frame_num + 1), y_vals, 'g.', label='y')\n",
        "        # ax.plot(range(0, frame_num + 1), z_vals, 'b.', label='z')\n",
        "        # ax.legend(loc='upper left')\n",
        "        # plt.draw()\n",
        "        plt.pause(0.00000000001)\n",
        "        clear_output(wait=True)\n",
        "        frame_num += 1\n",
        "    \n",
        "    # Convert the image back to BGR format for display\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Display the image\n",
        "    cv2.imshow('Pose Tracking', image)\n",
        "\n",
        "    # Wait for user input to exit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "    \n",
        "\n",
        "# Release the video capture, close all windows, and clear the plot\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the pose coordinates\n",
        "[pose_coords[i].landmark[0].y for i in range(len(pose_coords))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_landmarks_plot3D_animation(\"videos/clip_training_session_2.mp4\", \n",
        "                                  \"videos/clip_training_session_2_landmarks3D.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignoring empty camera frame.\n",
            "Joint Trace graph created!\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "video_path = \"./videos/clip_training_session_2.mp4\"\n",
        "body_part_index = 31\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "\n",
        "# Create an empty list to store the trace of the body part being tracked\n",
        "trace = []\n",
        "\n",
        "with mp_pose.Pose(min_detection_confidence=0.5,\n",
        "                  min_tracking_confidence=0.5) as pose:\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            print(\"Ignoring empty camera frame.\")\n",
        "            break\n",
        "\n",
        "        # Convert the frame to RGB format\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the frame with MediaPipe Pose model\n",
        "        results = pose.process(image)\n",
        "\n",
        "        # Check if any body parts are detected\n",
        "        if results.pose_landmarks:\n",
        "            # Get the x,y coordinates of the body part being tracked (in this case, the right elbow)\n",
        "            x, y = int(results.pose_landmarks.landmark[body_part_index].x * image.shape[1]), int(results.pose_landmarks.landmark[body_part_index].y * image.shape[0])\n",
        "\n",
        "            # Add the coordinates to the trace list\n",
        "            trace.append((x, y))\n",
        "\n",
        "            # Plot the trace on the graph\n",
        "            fig, ax = plt.subplots()\n",
        "            #ax.imshow(image)\n",
        "            ax.set_xlim(300,1000)\n",
        "            ax.set_ylim(200,800)\n",
        "            ax.invert_yaxis()\n",
        "            ax.plot(np.array(trace)[:, 0], np.array(trace)[:, 1], color='r')\n",
        "            plt.pause(0.00000000001)\n",
        "            clear_output(wait=True)\n",
        "            # Display the graph\n",
        "            #plt.show()\n",
        "        \n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "    \n",
        "    cap.release()\n",
        "    print(\"Joint Trace graph created!\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "explore",
      "language": "python",
      "name": "explore"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
